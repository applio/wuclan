---
layout: default
title:  mrflip.github.com/wuclan
collapse: false
---

h1(gemheader). {{ site.gemname }} %(small):: Social Graph Chainsaw%

p(description). {{ site.description }}

<div class="toggle"><h2>About Wuclan</h2>

Wuclan uses "Wukong":http://mrflip.github.com/wukong (Hadoop massive-data processing made easy) and "Monkeyshines":http://mrflip.github.com/monkeyshines (massive-scale directed scraper) to grok the deep structure of social networks. It is designed to scrape in a way that respectful of the terms and technical limits of each site while being agressive and efficient with your resources. We use it in practice to collect and analyze social graphs as large as 50 million-nodes, 1 billion-edges, 500 GB raw data  -- all of it actual data extracted in compliance with the site's terms of service.

Currently wuclan handles:

* Twitter -- API
* Twitter -- Search
* Twitter -- Hosebird
* Last.fm
* Opensocial

h2. Why?

APIs are nice and all, but they prevent any insight into a) global properties, or b) deep structure.  You can't find global word frequency and dispersion, or average clustering coefficient, or calculate pagerank, or determine weighted-shortest-paths connections between two people through an API call.  But with a 10 machine hadoop cluster and a good-sized collection of data, you can (and wuclan has scripts to help answer many of those questions).

Wuclan is strictly meant for such massive-scale investigations. Unless you're planning to do your final analysis on either hadoop or an enterprise-grade database system it's probably not worth the hassle.

</div><div class="toggle"><h2>Wuclan: Scraping</h2>

is almost ready for public use. Check back shortly.

</div><div class="toggle"><h2>Wuclan: Analysis</h2>

actually most of this still lives in the imw_twitter_friends repo.

</div><div class="toggle"><h2>More info</h2>

There are many useful examples in the examples/ directory.

h3. Authors

Philip (flip) Kromer (flip@infochimps.org)

Patches submitted by:

</div>

{% include news.html %}
